{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "\n",
    "I) Belleza del código.\n",
    "\n",
    "    1) Convertir listas en numpy array.\n",
    "    \n",
    "II) Preprocesamiento, ML, yerbas...\n",
    "\n",
    "    1) (http://scikit-learn.org/stable/modules/preprocessing.html#scaling-data-with-outliers]Probar \"robust_scale and RobustScaler\" en vez de normalization de los datos\n",
    "    2) Probar Grid_SearchCV en vez del \"for\"\n",
    "    \n",
    "III) Probar más hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python 2 \n",
    "from __future__ import division\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Time measurement\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "# Visu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The Hashing Trick\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# Dimension Reduction\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# ML\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Scoring\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations = pd.read_csv('data/station.csv')\n",
    "\n",
    "trips = pd.read_csv('data/trip_train.csv', parse_dates=['start_date','end_date'], infer_datetime_format=True, low_memory=False)\n",
    "\n",
    "weather = pd.read_csv('data/weather.csv', parse_dates=['date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trips['date'] = pd.to_datetime(trips.start_date.dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_number_of_trips = trips['duration'].shape[0]\n",
    "\n",
    "trip_length = 60*60*12     # seconds in 12 hours\n",
    "trips_larger_than_12_hour = trips[trips['duration'] > trip_length]['duration'].sum()\n",
    "trips_shorter_than_12_hour = trips[trips['duration'] < trip_length]['duration'].sum()\n",
    "ratio = trips_larger_than_12_hour/trips_shorter_than_12_hour\n",
    "print (trips_larger_than_12_hour,\"/\",trips_shorter_than_12_hour,'=',ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Histograma de duracion de viajes\")\n",
    "plt.xlabel('frecuencia')\n",
    "plt.ylabel('Duracion')\n",
    "plt.hist(x=trips[trips['duration'] < trip_length]['duration'],bins=200)\n",
    "plt.show()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = trips[trips['duration'] < trip_length]\n",
    "print (\"Total de viajes luego de remover outliers: \" + str(trips.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'city': ['San Jose','Redwood City','Mountain View', 'Palo Alto', 'San Francisco'],\\\n",
    "         'zip_code':[95113,94063,94041,94301,94107]}\n",
    "city_zip_codes = pd.DataFrame(data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stations = pd.merge(stations, city_zip_codes, on='city', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# se agrega el zip_code de la ciudad de la start station a cada viaje\n",
    "stations_to_join = stations.loc[:,['id','zip_code']]\n",
    "stations_to_join.columns = ['start_station_id','city_zip_code']\n",
    "\n",
    "trips = pd.merge(trips, stations_to_join, on='start_station_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.rename(columns={'zip_code':'city_zip_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather.precipitation_inches = pd.to_numeric(weather.precipitation_inches, errors='coerse')\n",
    "weather.precipitation_inches.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(trips, weather, on=['date','city_zip_code'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformar cada date en segundos desde 29/04/1994\n",
    "data.start_date = data.start_date.apply(lambda x: int((x - datetime.datetime(1994,4,29)).total_seconds()))\n",
    "\n",
    "data.end_date = data.end_date.apply(lambda x: int((x - datetime.datetime(1994,4,29)).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=['id','start_station_name','end_station_name','date','zip_code','bike_id'], axis=1, inplace=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_test = pd.read_csv('data/trip_test.csv', parse_dates=['start_date','end_date'], infer_datetime_format=True)\n",
    "trip_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# se agrega el zip_code de la ciudad de la start station a cada viaje del set de test\n",
    "trip_test = pd.merge(trip_test, stations_to_join, on='start_station_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_test['date'] = pd.to_datetime(trip_test.start_date.dt.date)\n",
    "\n",
    "trip_test = pd.merge(trip_test, weather, on=['date','city_zip_code'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformar cada date en segundos desde 29/04/1994\n",
    "trip_test.start_date = trip_test.start_date.apply(lambda x: int((x - datetime.datetime(1994,4,29)).total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_test.drop(labels=['id','start_station_name','end_station_name','date','zip_code','bike_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Hashing Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "column_labels = ['start_station_id','end_station_id','subscription_type','city_zip_code','events']\n",
    "\n",
    "for row in data.loc[:,column_labels].iterrows():\n",
    "    index, value = row\n",
    "    for i in range(len(value)):\n",
    "        value[i] = str(value[i])\n",
    "    temp.append(value.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = FeatureHasher(n_features=10, input_type='string')\n",
    "f = h.transform(raw_X=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de dispersidad: \" + str((f.nnz/(f.shape[0] * f.shape[1]))*100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data,pd.DataFrame(f.todense())],axis=1)\n",
    "data.drop(labels=column_labels,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verificamos que sean todos numericos\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.dropna(how='any').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Cantidad de muestras en train set: \"+str(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separamos y de x\n",
    "target_values = data['duration']\n",
    "data.drop(labels='duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scaler normaliza test y train set de la misma manera.](http://scikit-learn.org/stable/modules/preprocessing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(data)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scaler.transform(data) # devuelve una matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = (data - data.mean()) / (data.max() - data.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u,s,v = np.linalg.svd(data,full_matrices=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energía de la matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.xlabel(\"# valor singular\")\n",
    "plt.ylabel('Valor singular')\n",
    "plt.title(\"Energia de la matriz\")\n",
    "plt.plot(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos un codo en x = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aproximation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dim = 5\n",
    "closeness = np.isclose(np.dot(np.dot(u[:,0:dim],np.diag(s)[0:dim,0:dim]),v[0:dim,:]),data,atol=0.1,rtol=0.1)\n",
    "print (str((closeness.sum()/(closeness.shape[0]*closeness.shape[1])*100).round(2)) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated SVD\n",
    "\n",
    "[...it can work with scipy.sparse matrices efficiently.](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=10, n_iter=7, random_state=42)\n",
    "truncated_svd_aprox = svd.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_data = truncated_svd_aprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_neighbors = np.array(range(10,1001,10))\n",
    "metrics = ['euclidean', 'manhattan']\n",
    "KNN_cv_scores = np.zeros(shape=(len(k_neighbors),len(metrics)))\n",
    "\n",
    "for i,k in enumerate(k_neighbors):\n",
    "    for j,metric in enumerate(metrics):\n",
    "        \n",
    "        knn = neighbors.KNeighborsRegressor(n_neighbors=k, metric=metric, weights = 'distance',n_jobs=-1)\n",
    "        scores = cross_val_score(knn, reduced_data, target_values, cv=10, scoring='neg_mean_squared_error')\n",
    "        KNN_cv_scores[i][j] = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_cv_scores.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn con data normalization ,truncatedSVD, k = 20 --> array([[-5351858.19, -5360234.74]])\n",
    "\n",
    "knn con data normalization ,SVD, k = 40 --> array([[-5253803.39, -5260328.7 ]])\n",
    "\n",
    "knn con data standarization ,truncatedSVD (7 dim), k = 40 --> array([[-4737871.4 , -4733945.79]])\n",
    "\n",
    "knn con data standarization ,truncatedSVD (10 dim), k = 40 --> array([[-4491750.19, -4483791.72]]) <-------------\n",
    "\n",
    "knn con data standarization ,SVD, k = 40 --> array([[-5066280.98, -5021462.32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNN_cv_scores = np.array([[-6134361.15, -6079000.66],\n",
    "\t\t\t\t\t  [-5351858.19, -5360234.74],\n",
    "\t\t\t\t\t  [-5096953.65, -5095805.17],\n",
    "\t\t\t\t\t  [-4982807.73, -4969350.65],\n",
    "\t\t\t\t\t  [-4907901.23, -4890164.21],\n",
    "\t\t\t\t\t  [-4852908.1 , -4834866.28],\n",
    "\t\t\t\t\t  [-4817307.43, -4797754.1 ],\n",
    "\t\t\t\t\t  [-4790579.12, -4769114.32],\n",
    "\t\t\t\t\t  [-4767948.63, -4745718.41],\n",
    "\t\t\t\t\t  [-4751342.63, -4727356.28],\n",
    "\t\t\t\t\t  [-4739709.84, -4711076.88],\n",
    "\t\t\t\t\t  [-4726830.06, -4696665.8 ],\n",
    "\t\t\t\t\t  [-4715715.18, -4687716.97],\n",
    "\t\t\t\t\t  [-4706229.36, -4678451.76],\n",
    "\t\t\t\t\t  [-4697689.8 , -4670741.08],\n",
    "\t\t\t\t\t  [-4691308.05, -4665357.65],\n",
    "\t\t\t\t\t  [-4684562.35, -4659308.18],\n",
    "\t\t\t\t\t  [-4677509.1 , -4653394.41],\n",
    "\t\t\t\t\t  [-4672237.78, -4648805.1 ],\n",
    "\t\t\t\t\t  [-4667755.94, -4644264.32],\n",
    "\t\t\t\t\t  [-4662907.25, -4640719.22],\n",
    "\t\t\t\t\t  [-4658321.77, -4637249.78],\n",
    "\t\t\t\t\t  [-4654066.51, -4632933.27],\n",
    "\t\t\t\t\t  [-4650221.86, -4629486.34],\n",
    "\t\t\t\t\t  [-4646538.86, -4627016.1 ],\n",
    "\t\t\t\t\t  [-4642953.85, -4623886.01],\n",
    "\t\t\t\t\t  [-4639515.33, -4621242.79],\n",
    "\t\t\t\t\t  [-4636040.7 , -4618465.53],\n",
    "\t\t\t\t\t  [-4632803.81, -4615791.91],\n",
    "\t\t\t\t\t  [-4629935.04, -4613384.22],\n",
    "\t\t\t\t\t  [-4626602.03, -4611437.69],\n",
    "\t\t\t\t\t  [-4623721.83, -4608700.33],\n",
    "\t\t\t\t\t  [-4620566.86, -4606371.71],\n",
    "\t\t\t\t\t  [-4617386.36, -4604447.74],\n",
    "\t\t\t\t\t  [-4614419.37, -4603139.35],\n",
    "\t\t\t\t\t  [-4611734.2 , -4601562.83],\n",
    "\t\t\t\t\t  [-4609026.51, -4600178.79],\n",
    "\t\t\t\t\t  [-4607345.74, -4598160.78],\n",
    "\t\t\t\t\t  [-4605116.73, -4596688.19],\n",
    "\t\t\t\t\t  [-4603376.65, -4595194.93],\n",
    "\t\t\t\t\t  [-4601587.53, -4593121.06],\n",
    "\t\t\t\t\t  [-4600001.43, -4591552.04],\n",
    "\t\t\t\t\t  [-4598164.87, -4589910.62],\n",
    "\t\t\t\t\t  [-4596167.67, -4588453.26],\n",
    "\t\t\t\t\t  [-4594644.11, -4587628.87],\n",
    "\t\t\t\t\t  [-4593058.82, -4586432.97],\n",
    "\t\t\t\t\t  [-4591440.79, -4585359.34],\n",
    "\t\t\t\t\t  [-4590444.87, -4584486.15],\n",
    "\t\t\t\t\t  [-4588931.37, -4583458.19],\n",
    "\t\t\t\t\t  [-4587514.33, -4582651.52],\n",
    "\t\t\t\t\t  [-4585932.58, -4581528.13],\n",
    "\t\t\t\t\t  [-4584639.75, -4580836.93],\n",
    "\t\t\t\t\t  [-4583219.7 , -4579824.95],\n",
    "\t\t\t\t\t  [-4582349.66, -4579051.76],\n",
    "\t\t\t\t\t  [-4581703.28, -4578455.81],\n",
    "\t\t\t\t\t  [-4580664.6 , -4577890.98],\n",
    "\t\t\t\t\t  [-4579859.66, -4577140.71],\n",
    "\t\t\t\t\t  [-4578952.79, -4576545.1 ],\n",
    "\t\t\t\t\t  [-4578190.6 , -4576011.88],\n",
    "\t\t\t\t\t  [-4577508.68, -4575313.46],\n",
    "\t\t\t\t\t  [-4576812.1 , -4574810.81],\n",
    "\t\t\t\t\t  [-4576117.07, -4574246.79],\n",
    "\t\t\t\t\t  [-4575456.42, -4573528.77],\n",
    "\t\t\t\t\t  [-4575079.77, -4572995.22],\n",
    "\t\t\t\t\t  [-4574456.42, -4572555.19],\n",
    "\t\t\t\t\t  [-4573733.31, -4572173.41],\n",
    "\t\t\t\t\t  [-4572835.86, -4571679.54],\n",
    "\t\t\t\t\t  [-4571944.24, -4571347.05],\n",
    "\t\t\t\t\t  [-4571243.67, -4570827.76],\n",
    "\t\t\t\t\t  [-4570673.91, -4570314.32],\n",
    "\t\t\t\t\t  [-4570125.56, -4569726.02],\n",
    "\t\t\t\t\t  [-4569402.35, -4569275.26],\n",
    "\t\t\t\t\t  [-4568853.66, -4568817.24],\n",
    "\t\t\t\t\t  [-4568299.57, -4568358.15],\n",
    "\t\t\t\t\t  [-4567749.82, -4567980.21],\n",
    "\t\t\t\t\t  [-4567306.32, -4567479.81],\n",
    "\t\t\t\t\t  [-4566973.99, -4567107.05],\n",
    "\t\t\t\t\t  [-4566390.23, -4566979.09],\n",
    "\t\t\t\t\t  [-4566209.39, -4566688.21],\n",
    "\t\t\t\t\t  [-4565677.62, -4565677.62]])\n",
    "\n",
    "KNN_cv_scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(KNN_cv_scores[:,1])\n",
    "plt.title(\"Error de KNN\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"neg_mean_squared_error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print (np.array(KNN_cv_scores).round(2)\n",
    "\n",
    "# Estos prints están mal\n",
    "\n",
    "print (\"Best MSE: \" + str(np.array(KNN_cv_scores).round(2).max()))\n",
    "print (\"Index of best MSE: \" + str (np.array(KNN_cv_scores).round(2).argmax(axis=0)))\n",
    "print (\"Best k: \" + str(k_neighbors[KNN_cv_scores.round(2).argmax(axis=1)[0]]) )\n",
    "print (\"Best metric: \" + str(metrics[KNN_cv_scores.round(2).argmax(axis=1)[1]] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = neighbors.KNeighborsRegressor(n_neighbors=40, metric='manhattan', weights = 'distance', n_jobs=-1)\n",
    "bagging = BaggingRegressor(KNN, n_estimators=20, oob_score=True, n_jobs=-1, max_samples=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "bagging.fit(reduced_data, target_values)\n",
    "print(\"bagging with knn took %.2f seconds\" % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_depth = np.array(range(10,1001,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_scores = []\n",
    "\n",
    "for current_depth in possible_depth:\n",
    "    \n",
    "    regr_1 = DecisionTreeRegressor(max_depth=current_depth)\n",
    "    scores = cross_val_score(regr_1, data, target_values, cv=10, scoring='neg_mean_squared_error')\n",
    "    DTR_cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Best MSE: \" + str(np.array(cv_scores).round(2).max()))\n",
    "print (\"Index of best MSE: \" + str (np.array(cv_scores).round(2).argmax()))\n",
    "print (\"Best depth: \" + str(possible_depth[np.array(cv_scores).round(2).argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.scatter(x=range(len(y_1)),y=y_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.ylim(0,531240)\n",
    "plt.scatter(x=range(len(Y_test)),y=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "                'max_depth':[5,6,7,8,9,10],\n",
    "                'max_features':[1,2,3,5,7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr_2 = RandomForestRegressor(n_estimators=50, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(regr_2, param_grid=parameters, n_jobs=-1, scoring='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "grid_search.fit(data, target_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "print(\"Best score: \", grid_search.best_score_ , \"Best parameters setting: \",grid_search.cv_results_['params'][grid_search.best_index_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
